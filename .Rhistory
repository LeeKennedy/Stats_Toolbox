describe(bucket)
describe(data.in$A)
sd(bucket)*sqrt(200)
sd(data.in$A)
#### Clean Up environment -----------------------------
rm(list=ls())
#### Packages -----------------------------
library(readxl)
library(tidyverse)
library(LK.Toolbox)
library(psych)
library(here)
#### Functions -----------------------------
#### Data Input -----------------------------
here::here()
data.in <- read_excel("data/Book1.xlsx")
data.in$A <- as.numeric(data.in$A)
bucket <- rep(NA,10000)
n <- nrow(data.in)
for(i in 1:10000){
samp = sample(data.in$A, n, replace=TRUE)
bucket[i] = mean(samp)
}
hist(bucket, breaks = 20)
summary(bucket)
describe(bucket)
describe(data.in$A)
#### Clean Up environment -----------------------------
rm(list=ls())
#### Packages -----------------------------
library(readxl)
library(tidyverse)
library(LK.Toolbox)
library(psych)
library(here)
#### Functions -----------------------------
#### Data Input -----------------------------
here::here()
data.in <- read_excel("data/Book1.xlsx")
data.in$A <- as.numeric(data.in$A)
bucket <- rep(NA,10000)
n <- nrow(data.in)
for(i in 1:10000){
samp = sample(data.in$A, n, replace=TRUE)
bucket[i] = mean(samp)
}
hist(bucket, breaks = 20)
summary(bucket)
describe(bucket)
describe(bucket, skew = FALSE)
#### Clean Up environment -----------------------------
rm(list=ls())
#### Packages -----------------------------
library(readxl)
library(tidyverse)
library(LK.Toolbox)
library(psych)
library(here)
#### Functions -----------------------------
#### Data Input -----------------------------
here::here()
data.in <- read_excel("data/Book1.xlsx")
data.in$A <- as.numeric(data.in$A)
bucket <- rep(NA,10000)
n <- nrow(data.in)
for(i in 1:10000){
samp = sample(data.in$A, n, replace=TRUE)
bucket[i] = mean(samp)
}
hist(bucket, breaks = 20)
summary(bucket)
describe(bucket, skew = FALSE)
hist(bucket, breaks = 40)
# Clean Up environment ---------------------------------------------------
rm(list=ls())
# Packages ---------------------------------------------------------------
library(tidyverse)
library(LK.Toolbox)
library(readxl)
# Functions --------------------------------------------------------------
cohens_d <- function(x, y) {
lx <- length(x)- 1
ly <- length(y)- 1
md  <- abs(mean(x) - mean(y))
csd <- lx * var(x) + ly * var(y)
csd <- csd/(lx + ly)
csd <- sqrt(csd)
cd  <- md/csd   ## cohen's d
}
# Data Input -------------------------------------------------------------
data.in <- read_excel("data/Book1.xlsx")
# Data Cleaning ----------------------------------------------------------
data.in <- data.in[1:15,]
t1 <- data.in$A
t2 <- data.in$B
boxplot(t1, t2)
summary(data.in)
t.test(t2, t1, paired = TRUE)
aa <- cohens_d(data.in$A, data.in$B)
round(aa,2)
# Packages ---------------------------------------------------------------
library(tidyverse)
library(LK.Toolbox)
library(readxl)
cohens_d <- function(x, y) {
lx <- length(x)- 1
ly <- length(y)- 1
md  <- abs(mean(x) - mean(y))
csd <- lx * var(x) + ly * var(y)
csd <- csd/(lx + ly)
csd <- sqrt(csd)
cd  <- md/csd   ## cohen's d
}
data.in <- read_excel("data/Book1.xlsx")
# Clean Up environment ---------------------------------------------------
rm(list=ls())
# Packages ---------------------------------------------------------------
library(tidyverse)
library(LK.Toolbox)
library(readxl)
# Functions --------------------------------------------------------------
cohens_d <- function(x, y) {
lx <- length(x)- 1
ly <- length(y)- 1
md  <- abs(mean(x) - mean(y))
csd <- lx * var(x) + ly * var(y)
csd <- csd/(lx + ly)
csd <- sqrt(csd)
cd  <- md/csd   ## cohen's d
}
# Data Input -------------------------------------------------------------
data.in <- read_excel("data/Book1.xlsx")
data.in <- data.in[1:15,]
t1 <- data.in$A
t2 <- data.in$B
boxplot(t1, t2)
summary(data.in)
?summary
summary(data.in[,2:3])
t.test(t2, t1, paired = TRUE)
aa <- cohens_d(data.in$A, data.in$B)
round(aa,2)
data.in <- data.in[16:30,]
t1 <- data.in$A
t2 <- data.in$B
boxplot(t1, t2)
# Clean Up environment ---------------------------------------------------
rm(list=ls())
# Packages ---------------------------------------------------------------
library(tidyverse)
library(LK.Toolbox)
library(readxl)
# Functions --------------------------------------------------------------
cohens_d <- function(x, y) {
lx <- length(x)- 1
ly <- length(y)- 1
md  <- abs(mean(x) - mean(y))
csd <- lx * var(x) + ly * var(y)
csd <- csd/(lx + ly)
csd <- sqrt(csd)
cd  <- md/csd   ## cohen's d
}
# Data Input -------------------------------------------------------------
data.in <- read_excel("data/Book1.xlsx")
# Data Cleaning ----------------------------------------------------------
data.in <- data.in[16:30,]
t1 <- data.in$A
t2 <- data.in$B
boxplot(t1, t2)
summary(data.in[,2:3])
t.test(t2, t1, paired = TRUE)
aa <- cohens_d(data.in$A, data.in$B)
round(aa,2)
# Insert mean and std deviation into A, B & C.  Add other variables, as needed.
library(dplyr)
# Insert appropriate values --------------------------------------------------
Result_Mean <- 4.5
Result_sd_r <- 0.3
Result_sd_R <- 0.806
# Set the data matrix --------------------------------------------------------
A <- rnorm(100000, Result_Mean, Result_sd_R)
B <- rnorm(100000, Result_Mean, Result_sd_R)
B1 <- rnorm(100000, B, Result_sd_r)
B2 <- rnorm(100000, B, Result_sd_r)
# Combine to create sets -----------------------------------------------------
Set <- as.data.frame(cbind(A,B1,B2))
Range <- numeric(100000)
Range <-as.data.frame(t(apply(Set[,c(1:3)],1,range)))
Eqn <- Range %>%
mutate(Diff = V2-V1)
# Calc means and sd for composite value --------------------------------------
Em <- mean(Eqn$Diff)
Esd <- sd(Eqn$Diff)
k <- 1.98
Range_max <- Em + k*Esd
# Histogram of ranges --------------------------------------------------------
hist(Eqn$Diff, breaks=30)
#Maximum range of results for a single test and two retests ------------------
Range_max
# Insert mean and std deviation into A, B & C.  Add other variables, as needed.
library(dplyr)
# Insert appropriate values --------------------------------------------------
Result_Mean <- 4.5
Result_sd_r <- 0.03
Result_sd_R <- 0.106
# Set the data matrix --------------------------------------------------------
A <- rnorm(100000, Result_Mean, Result_sd_R)
B <- rnorm(100000, Result_Mean, Result_sd_R)
A1 <- rnorm(100000, A, Result_sd_r)
A2 <- rnorm(100000, A, Result_sd_r)
B1 <- rnorm(100000, B, Result_sd_r)
B2 <- rnorm(100000, B, Result_sd_r)
# Combine to create sets -----------------------------------------------------
Set <- as.data.frame(cbind(A1,A2,B1,B2))
Range <- numeric(100000)
Range <-as.data.frame(t(apply(Set[,c(1:4)],1,range)))
Eqn <- Range %>%
mutate(Diff = V2-V1)
# Calc means and sd for composite value --------------------------------------
Em <- mean(Eqn$Diff)
Esd <- sd(Eqn$Diff)
k <- 1.98
Range_max <- Em + k*Esd
# Histogram of ranges --------------------------------------------------------
hist(Eqn$Diff, breaks=30)
# Insert mean and std deviation into A, B & C.  Add other variables, as needed.
A <- rnorm(10000, 83, 2.5)
B <- rnorm(10000, 33.10, 2.5)
#C <- rnorm(10000, 3, 0.2)
# Create an equation:
Eqn <- (A - B)*100/A
# Calc means and sd for composite value:
Em <- mean(Eqn)
Esd <- sd(Eqn)
k <- 1.98
E.mu <- k*Esd
Em
Esd
k
E.mu
hist(Eqn, breaks=30)
library(dplyr)
library(ggplot2)
#---- Set number of replicates -------------------------------------------
n <- 10000
#---- Set compositional parameters (Mean & sd) ---------------------------
moisture_result <- 40
moisture_sd   <- 0.47
ash_result <- 4
ash_sd   <- 0.07
fat_result <- 10
fat_sd   <- 0.32
prot_result <- 8.0
prot_sd   <- 0.27
df_result <- 1.3
df_sd   <- 0.47
# --- Create random data -------------------------------------------------
MOIST <- rnorm(n, moisture_result, moisture_sd)
ASH <- rnorm(n, ash_result, ash_sd)
FAT <- rnorm(n, fat_result, fat_sd)
PROT <- rnorm(n, prot_result, prot_sd)
DF <- rnorm(n, df_result, df_sd)
# ---- Create dataframe --------------------------------------------------
nip <- as.data.frame(cbind(MOIST, ASH, FAT, PROT, DF))
# ---- Create CHO & kJ data ----------------------------------------------
nip <- nip %>%
mutate(CHO = 100-MOIST-ASH-FAT-PROT-DF,
KJ = 37*FAT+17*(PROT + CHO))
# ---- Create CHO & kJ summary -------------------------------------------
cho_kj <- nip %>%
summarise(CHO_mean = round(mean(CHO),2),
CHO_mu = round(2*sd(CHO),2),
KJ_mean = round(mean(KJ),0),
KJ_sd = round(2*sd(KJ),0))
# ---- Determine limits --------------------------------------------------
limits_CHO <- quantile(nip$CHO, c(0.025, 0.975))
limits_KJ <- quantile(nip$KJ, c(0.025, 0.975))
# ---- Plot Histograms ---------------------------------------------------
plot_CHO <- ggplot(nip, aes(x=CHO)) +
geom_histogram(binwidth = 0.2, colour = "darkgreen", fill = "burlywood1") +
geom_vline(xintercept = limits_CHO[1], lty=2, colour = "red") +
geom_vline(xintercept = limits_CHO[2], lty=2, colour = "red") +
theme_bw()
plot_CHO
plot_KJ <- ggplot(nip, aes(x=KJ)) +
geom_histogram(binwidth = 2, colour = "darkgreen", fill = "burlywood1") +
geom_vline(xintercept = limits_KJ[1], lty=2, colour = "red") +
geom_vline(xintercept = limits_KJ[2], lty=2, colour = "red") +
theme_bw()
plot_KJ
# ---- Print summary data ------------------------------------------------
cho_kj
library(dplyr)
library(ggplot2)
#---- Set number of replicates -------------------------------------------
n <- 10000
#---- Set compositional parameters (Mean & sd) ---------------------------
moisture_result <- 40
moisture_sd   <- 0.47
ash_result <- 4
ash_sd   <- 0.07
fat_result <- 10
fat_sd   <- 0.32
prot_result <- 8.0
prot_sd   <- 0.27
df_result <- 1.3
df_sd   <- 0.47
# --- Create random data -------------------------------------------------
MOIST <- rnorm(n, moisture_result, moisture_sd)
ASH <- rnorm(n, ash_result, ash_sd)
FAT <- rnorm(n, fat_result, fat_sd)
PROT <- rnorm(n, prot_result, prot_sd)
DF <- rnorm(n, df_result, df_sd)
# ---- Create dataframe --------------------------------------------------
nip <- as.data.frame(cbind(MOIST, ASH, FAT, PROT, DF))
# ---- Create CHO & kJ data ----------------------------------------------
nip <- nip %>%
mutate(CHO = 100-MOIST-ASH-FAT-PROT-DF,
KJ = 37*FAT+17*(PROT + CHO))
# ---- Create CHO & kJ summary -------------------------------------------
cho_kj <- nip %>%
summarise(CHO_mean = round(mean(CHO),2),
CHO_mu = round(2*sd(CHO),2),
KJ_mean = round(mean(KJ),0),
KJ_sd = round(2*sd(KJ),0))
# ---- Determine limits --------------------------------------------------
limits_CHO <- quantile(nip$CHO, c(0.025, 0.975))
limits_KJ <- quantile(nip$KJ, c(0.025, 0.975))
# ---- Plot Histograms ---------------------------------------------------
plot_CHO <- ggplot(nip, aes(x=CHO)) +
geom_histogram(binwidth = 0.2, colour = "darkgreen", fill = "burlywood1") +
geom_vline(xintercept = limits_CHO[1], lty=2, colour = "red") +
geom_vline(xintercept = limits_CHO[2], lty=2, colour = "red") +
theme_bw()
plot_CHO
plot_KJ <- ggplot(nip, aes(x=KJ)) +
geom_histogram(binwidth = 2, colour = "darkgreen", fill = "burlywood1") +
geom_vline(xintercept = limits_KJ[1], lty=2, colour = "red") +
geom_vline(xintercept = limits_KJ[2], lty=2, colour = "red") +
theme_bw()
plot_KJ
# ---- Print summary data ------------------------------------------------
cho_kj
# Data for comparing two paired data sets
n <- 73
xdiff.bar <- 12.76
sd.diff <- 14.26
SEdiff <- sd.diff/sqrt(n)
# Ho is the proposed null difference.
Ho <- 0
z <- (xdiff.bar-Ho)/SEdiff
# Two sided
2*(1-pnorm(z))
# t value
t1 <- qt(0.975,n-1)
CI.lower <- xdiff.bar-1.96*SEdiff
CI.upper <- xdiff.bar+1.96*SEdiff
CI.lower.t <- xdiff.bar-t1*SEdiff
CI.upper.t <- xdiff.bar+t1*SEdiff
library(ggplot2)
ggplot(data.frame(x = c(-20, 20)), aes(x)) +
stat_function(fun = dnorm, args = list(mean = 0, sd = SEdiff)) +
geom_vline(xintercept=xdiff.bar, lty=2, col = "red")
# R Statistics Essential Training
# Ex07_03
# Comparing means with the t-test
# Load data
?sleep
sleep[1:5, ]
sd <- sleep[, 1:2]  # Save just the first two variables
sd[1:5, ]  # Show the first 5 cases
# Some quick plots to check data
hist(sd$extra, col = "lightgray")
boxplot(extra ~ group, data = sd)
# Independent 2-group t-test (with defaults)
t.test(extra ~ group, data = sd)
# t-test with options
t.test(extra ~ group,
data = sd,
alternative = "less",  # One-tailed test
conf.level = 0.80)  # 80% CI (vs. 95%)
# Create two groups of random data in separate variables
# Good because actual difference is known
x <- rnorm(30, mean = 20, sd = 5)
y <- rnorm(30, mean = 22, sd = 5)
t.test(x, y)
rm(list = ls())  # Clean up
setwd("H:/GitHub Projects/Stats_Toolbox/data")
data.in <- read.csv("Test_equiv.csv", as.is=TRUE, header=TRUE)
library(equivalence)
options(warn=-1)  # to turn on warnings use options(warn=0)
boxplot(data.in)
Col1 <- colnames(data.in)
colnames(data.in) <- c("A", "B")
sdA <- sd(data.in$A, na.rm=TRUE)
sdB <- sd(data.in$B, na.rm=TRUE)
meanA <- mean(data.in$A, na.rm=TRUE)
meanB <- mean(data.in$B, na.rm=TRUE)
nA <- length(na.omit(data.in$A))
nB <- length(na.omit(data.in$B))
sdpooled <- sqrt(((nA-1)*sdA^2+(nB-1)*sdB^2)/(nA+nB-2))
#-----------estimating the acceptable maximum difference------------------
#-----------(reference?)--------------------------------------------------
s_star <- sdB*sqrt((nB-1)/(qchisq(0.99,(nB-1))))
delta <- 0
epsiln <- delta + s_star*(2*qt(0.95,(2*nB-2))*sqrt(2/nB))
#  Ho = the two sets are different. (The revers to the normal Ho.)
# "Not rejected" means that we have not proven that the two sets are equivalent.
#  Generally different if epsilon, the acceptable difference, > pooled sd.
tost_xy <- tost(data.in$A, data.in$B, alpha = 0.05, epsiln)
tost_xy
ll <- ((meanA+meanB)/2)-4*sdpooled
ul <- ((meanA+meanB)/2)+4*sdpooled
SetA <- function(x) dnorm(x, mean = meanA, sd = sdA)
SetB <- function(x) dnorm(x, mean = meanB, sd = sdB)
myYLim <- c(0, 0.01)
plot(SetA, from = ll, to = ul, ylim = myYLim, col = "red", lwd = 4, xlab = "", ylab = "")
plot(SetB, from = ll, to = ul, col = "blue", lwd = 4, add = TRUE)
abline(v = meanA)
abline(v = meanB)
#detach("package:equivalence", unload=TRUE)
# Data
x1 <- 6.78
s1 <- 1.43
n1 <- 50
x2 <- 7.18
s2 <- 1.6
n2 <- 100
Diff <- x2-x1
SEdiff <- sqrt((s2^2/n2)+(s1^2/n1))
CI.lower <- Diff-1.96*SEdiff
CI.upper <- Diff+1.96*SEdiff
# Null Hypothesis
Ho <- 0
z <- (Diff - Ho)/SEdiff
# One tail
1-pnorm(z)
# Two tail
2*(1-pnorm(z))
# t value
t1 <- qt(0.975,n1-1)
library(ggplot2)
ggplot(data.frame(x = c(-2, 2)), aes(x)) +
stat_function(fun = dnorm, args = list(mean = 0, sd = SEdiff)) +
geom_vline(xintercept=Diff, lty=2, col = "red")
#### Clean Up environment -----------------------------
rm(list=ls())
#### Packages -----------------------------
library(readxl)
library(tidyverse)
library(LK.Toolbox)
library(here)
#### Functions -----------------------------
#### Data Input -----------------------------
here()
data <-
# Optional strip_mm
#### Data Cleaning -----------------------------
#### Visualising Data -----------------------------
setwd("H:/GitHub Projects/Stats_Toolbox")
setwd("H:/GitHub Projects/Stats_Toolbox")
#### Clean Up environment -----------------------------
rm(list=ls())
#### Packages -----------------------------
library(readxl)
library(tidyverse)
library(LK.Toolbox)
library(equivalence)
library(here)
#### Data Input -----------------------------
here::here()
data.in <- read_excel("data/Test_equiv.xlsx")
boxplot(data.in)
sdA <- sd(data.in$A, na.rm=TRUE)
sdB <- sd(data.in$B, na.rm=TRUE)
meanA <- mean(data.in$A, na.rm=TRUE)
meanB <- mean(data.in$B, na.rm=TRUE)
nA <- length(na.omit(data.in$A))
nB <- length(na.omit(data.in$B))
sdpooled <- sqrt(((nA-1)*sdA^2+(nB-1)*sdB^2)/(nA+nB-2))
s_star <- sdB*sqrt((nB-1)/(qchisq(0.99,(nB-1))))
delta <- 0
epsiln <- delta + s_star*(2*qt(0.95,(2*nB-2))*sqrt(2/nB))
#  Ho = the two sets are different. (The revers to the normal Ho.)
# "Not rejected" means that we have not proven that the two sets are equivalent.
#  Generally different if epsilon, the acceptable difference, > pooled sd.
tost_xy <- tost(data.in$A, data.in$B, alpha = 0.05, epsiln)
tost_xy
ll <- ((meanA+meanB)/2)-4*sdpooled
ul <- ((meanA+meanB)/2)+4*sdpooled
SetA <- function(x) dnorm(x, mean = meanA, sd = sdA)
SetB <- function(x) dnorm(x, mean = meanB, sd = sdB)
myYLim <- c(0, 0.01)
plot(SetA, from = ll, to = ul, ylim = myYLim, col = "red", lwd = 4, xlab = "", ylab = "")
plot(SetB, from = ll, to = ul, col = "blue", lwd = 4, add = TRUE)
abline(v = meanA)
abline(v = meanB)
tost_plot <- ggplot(data.frame(x = c(ll, ul)), aes(x = x)) +
stat_function(fun = dnorm)
tost_plot
tost_plot <- ggplot(data.frame(x = c(ll, ul)), aes(x = x)) +
stat_function(fun = dnorm)
tost_plot
p9 <- ggplot(data.frame(x = c(-4, 4)), aes(x = x)) +
stat_function(fun = dnorm)
p9
tost_plot <- ggplot(data.frame(x = c(ll, ul)), aes(x = x)) +
stat_function(fun = dnorm)
tost_plot
tost_plot <- ggplot(data.frame(x = c(ll, ul), y = myYLim), aes(x = x)) +
stat_function(fun = dnorm)
tost_plot
